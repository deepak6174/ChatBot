{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b50ab5",
   "metadata": {},
   "source": [
    "# ChatBot to Recommend Movies and Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7710e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import string\n",
    "import nltk\n",
    "import random\n",
    "import warnings\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1cbfef",
   "metadata": {},
   "source": [
    "# <H1>Movie Recommendation ChatBot</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69ee762",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ratings.csv', mode='r') as file: \n",
    "    csvFile = csv.reader(file)\n",
    "    movie_ratings = {}\n",
    "    for line in csvFile:\n",
    "        if int(line[1]) not in movie_ratings:\n",
    "            movie_ratings[int(line[1])] = [float(line[2]), 1]\n",
    "        else:\n",
    "            movie_ratings[int(line[1])] = [float(line[2]) + movie_ratings[int(line[1])][0], movie_ratings[int(line[1])][1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06ed544",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movies.csv', mode='r') as file: \n",
    "    csvFile = csv.reader(file)\n",
    "    movie_name = {}\n",
    "    sent_token_movie = []\n",
    "    movie_name_token = []\n",
    "    movie_genres = {}\n",
    "    for line in csvFile:\n",
    "        sent_token_movie.append(str(line[0]) + \" \" + line[2].lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
    "        movie_name_token.append(str(line[0]) + \" \" + line[1].lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
    "        movie_name[int(line[0])] = line[1]  \n",
    "        movie_genres[int(line[0])] = line[2].lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a45015",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer() \n",
    "\n",
    "def LemTokens(tokens):\n",
    "  return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "\n",
    "def LemNormalize(text):\n",
    "  return LemTokens(nltk.word_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9c91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9964ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFirst(val):\n",
    "        return val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec4e2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepak/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TfidfVec_search_movie_genre = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "tfidf_search_movie_genre = TfidfVec_search_movie_genre.fit_transform(movie_name_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6423fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_movie_genre(user_query):\n",
    "   k = TfidfVec_search_movie_genre.transform([user_query.lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))])\n",
    "   vals = cosine_similarity(k, tfidf_search_movie_genre)\n",
    "   idx = vals.argsort()[0][-1]\n",
    "   flat = vals.flatten()\n",
    "   flat.sort()\n",
    "   req_tfidf = flat[-1]\n",
    "   if req_tfidf == 0:\n",
    "        return \"\", 0\n",
    "   else:\n",
    "        return movie_genres[int(movie_name_token[idx].split(\" \")[0])], int(movie_name_token[idx].split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2891cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVec_search_similar_genre = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "tfidf_search_similar_genre = TfidfVec_search_similar_genre.fit_transform(sent_token_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c5aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_genre(user_query):\n",
    "    query_tags, query_movie_id = search_movie_genre(user_query)\n",
    "    if query_tags == \"\":\n",
    "        return [], 0\n",
    "    if movie_name[query_movie_id].split(\"(\")[0].lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))[:-1] not in user_query.lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))):\n",
    "        return [], 0\n",
    "    k = TfidfVec_search_similar_genre.transform([query_tags.lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))])\n",
    "    vals = cosine_similarity(k, tfidf_search_similar_genre)\n",
    "    index = 0\n",
    "    val_with_index = []\n",
    "    for val in vals[0]:\n",
    "        tuple1 = (val, index)\n",
    "        val_with_index.append(tuple1)\n",
    "        index = index + 1\n",
    "    val_with_index.sort(key=sortFirst, reverse=True)\n",
    "    return val_with_index, query_movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e92291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_found_genre(user_query):\n",
    "    similarity_with_index, query_movie_id = find_similar_genre(user_query)\n",
    "    if query_movie_id == 0:\n",
    "        return [], 0\n",
    "    all_sorted_details = []\n",
    "    for swi in similarity_with_index:\n",
    "        movie_id = int(sent_token_movie[swi[1]].split(\" \")[0])\n",
    "        if movie_id == query_movie_id:\n",
    "            continue\n",
    "        if movie_id not in movie_ratings:\n",
    "            continue\n",
    "        movie_rating = movie_ratings[movie_id][0]/float(movie_ratings[movie_id][1])\n",
    "        all_sorted_details.append((swi[0], movie_rating, movie_name[movie_id], movie_genres[movie_id]))\n",
    "    all_sorted_details = sorted(all_sorted_details, key=lambda x:(-x[0], -x[1]))\n",
    "    rating_in_query = re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", user_query)\n",
    "    if len(rating_in_query) > 0 and float(rating_in_query[0]) <= 5 and float(rating_in_query[0]) >= 0:\n",
    "        remove_elements = []\n",
    "        for asd in all_sorted_details:\n",
    "            if asd[1] < float(rating_in_query[0]):\n",
    "                remove_elements.append(asd)\n",
    "        for remove_element in remove_elements:\n",
    "            all_sorted_details.remove(remove_element)\n",
    "    query_genre_tags = movie_genres[query_movie_id].split(\" \")\n",
    "    remove_elements = []\n",
    "    for all_sorted_detail in all_sorted_details:\n",
    "        flag = 0\n",
    "        for query_genre_tag in query_genre_tags:\n",
    "            if query_genre_tag in all_sorted_detail[3]:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            remove_elements.append(all_sorted_detail)\n",
    "    for remove_element in remove_elements:\n",
    "        all_sorted_details.remove(remove_element)\n",
    "    print(\"ChatBot: I found these similar movies:\")\n",
    "    for x in range(0,min(5, len(all_sorted_details))):\n",
    "        print(x + 1, \" \",all_sorted_details[x][2])\n",
    "    return all_sorted_details, query_movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b5e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot_movie(user_input):\n",
    "        all_sorted_details, query_movie_id = sort_found_genre(user_input)\n",
    "        if query_movie_id == 0:\n",
    "            print(\"ChartBot: There is no such movie I know.\")\n",
    "        elif len(all_sorted_details) == 0:\n",
    "            print(\"ChatBot: I couldn't find any similar movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b06ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_intent_data = {\"intents\": [\n",
    "    {\"tag\": \"greeting\",\n",
    "     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n",
    "     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n",
    "    },\n",
    "    {\"tag\": \"movie_chat_bot\",\n",
    "     \"patterns\": [\"find me a movie similar to\", \"what are the movies I can watch if I have seen\", \"I have seen find me something similar\", \"I had seen , tell me what to watch\"],\n",
    "     \"responses\": []\n",
    "    },\n",
    "    {\"tag\": \"restaurant_chat_pot\",\n",
    "     \"patterns\": [\"french dutch european vegetarian friendly\", \"gluten free options mediterranean international vegan\", \"contemporary asian indonesian japanese seafood\", \"fast food american bar central pub\", \"cafe british healthy indian tibetan nepali\", \"italian barbecue steakhouse latin argentinean\", \"south grill delicatessen pizza thai soups street diner\",\"lebanese middle eastern israeli new zealand chinese belgian\", \"sushi spanish korean turkish vietnamese irish german\", \"halal gastropub swiss scandinavian fusion\", \"arabic balti moroccan tunisian persian wine portuguese\", \"mexican australian greek caribbean african ethiopian\", \"brew southwestern singaporean malaysian minority\", \"peruvian taiwanese hawaiian jamaican\", \"kosher brazilian pakistani swedish norwegian\", \"afghani colombian ecuadorean austrian danish romanian\",\"cajun creole georgian egyptian cuban russian\", \"czech armenian venezuelan bangladeshi scottish azerbaijani\", \"hungarian filipino croatian polish yunnan cambodian\", \"chilean mongolian uzbek xinjiang albanian ukrainian\", \"sri lankan caucasian latvian salvadoran guatemalan\", \"native canadian slovenian polynesian puerto\", \"rican welsh burmese fujian\", \"what are the restaurant I can go to if I like\", \"find me a restaurant with their speciality in \", \"where can I go out for lunch dinner breakfast brunch\"],\n",
    "     \"responses\": []\n",
    "    },\n",
    "    {\"tag\": \"goodbye\",\n",
    "     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n",
    "    },\n",
    "    {\"tag\": \"thanks\",\n",
    "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n",
    "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n",
    "    },\n",
    "]}\n",
    "\n",
    "restaurant_intent_data = {\"intents\": [\n",
    "    {\"tag\": \"tags_not_found\",\n",
    "     \"patterns\": ['french', 'dutch', 'european', 'vegetarian', 'friendly', 'gluten', 'free', 'options', 'mediterranean', 'international', 'vegan', 'contemporary', 'asian', 'indonesian', 'japanese', 'seafood', 'fast', 'food', 'american', 'bar', 'central', 'pub', 'cafe', 'british', 'healthy', 'indian', 'tibetan', 'nepali', 'italian', 'barbecue', 'steakhouse', 'latin', 'argentinean', 'south', 'grill', 'delicatessen', 'pizza', 'thai', 'soups', 'street', 'diner', 'lebanese', 'middle', 'eastern', 'israeli', 'new', 'zealand', 'chinese', 'belgian', 'sushi', 'spanish', 'korean', 'turkish', 'vietnamese', 'irish', 'german', 'halal', 'gastropub', 'swiss', 'scandinavian', 'fusion', 'arabic', 'balti', 'moroccan', 'tunisian', 'persian', 'wine', 'portuguese', 'mexican', 'australian', 'greek', 'caribbean', 'african', 'ethiopian', 'brew', 'southwestern', 'singaporean', 'malaysian', 'minority', 'peruvian', 'taiwanese', 'hawaiian', 'jamaican', 'kosher', 'brazilian', 'pakistani', 'swedish', 'norwegian', 'afghani', 'colombian', 'ecuadorean', 'austrian', 'danish', 'romanian', 'cajun', 'creole', 'georgian', 'egyptian', 'cuban', 'russian', 'czech', 'armenian', 'venezuelan', 'bangladeshi', 'scottish', 'azerbaijani', 'hungarian', 'filipino', 'croatian', 'polish', 'yunnan', 'cambodian', 'chilean', 'mongolian', 'uzbek', 'xinjiang', 'albanian', 'ukrainian', 'sri', 'lankan', 'caucasian', 'latvian', 'salvadoran', 'guatemalan', 'native', 'canadian', 'slovenian', 'polynesian', 'puerto', 'rican', 'welsh', 'burmese', 'fujian'],\n",
    "     \"responses\": [\"What kind of speciality you want restaurants to have?\", \"What kind of food would you like to have?\", \"I can search any perticular type of restaurants\"]\n",
    "    },\n",
    "    {\"tag\": \"city_not_found\",\n",
    "     \"patterns\": ['amsterdam', 'athens', 'barcelona', 'berlin', 'bratislava', 'brussels', 'budapest', 'copenhagen', 'dublin', 'edinburgh', 'geneva', 'hamburg', 'helsinki', 'krakow', 'lisbon', 'ljubljana', 'london', 'luxembourg', 'lyon', 'madrid', 'milan', 'munich', 'oporto', 'oslo', 'paris', 'prague', 'rome', 'stockholm', 'vienna', 'warsaw', 'zurich'],\n",
    "     \"responses\": [\"Tell me the city you want the restaurant to be in\", \"I need the city info in order to search the restaurants\", \"In which city you want the restaurants to be found\"]\n",
    "    },\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea961fc5",
   "metadata": {},
   "source": [
    "# <H1> Restaurant Recommendation Chatbot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f03ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TA_restaurants_curated.csv', mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    sent_token = []\n",
    "    name_rating = []\n",
    "    city_tags = []\n",
    "    line_counter = 0\n",
    "    for lines in csvFile:\n",
    "        sentence = \"\"\n",
    "        col_num = 0\n",
    "        rating = \"\"\n",
    "        name = \"\"\n",
    "        for col in lines:\n",
    "            if col == \"\":\n",
    "                sentence = \"\"\n",
    "                break\n",
    "            col_num = col_num + 1\n",
    "            if col_num == 2:\n",
    "                name = col\n",
    "                continue\n",
    "            if col_num == 3:\n",
    "                if col.lower() not in city_tags:\n",
    "                    city_tags.append(col.lower())\n",
    "            if col_num == 5 or col_num == 1:\n",
    "                continue\n",
    "            if col_num == 6:\n",
    "                rating = col\n",
    "                break\n",
    "            if str(col) not in sentence:\n",
    "                sentence = sentence + str(col) + \" \"\n",
    "        if sentence != \"\":\n",
    "            sentence = sentence.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "            sentence = str(line_counter) + \" \" + sentence\n",
    "            line_counter = line_counter + 1\n",
    "            name_rating.append((float(rating), name))\n",
    "            sent_token.append(sentence + rating)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a947eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "tfidf = TfidfVec.fit_transform(sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a37a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_query):\n",
    "   k = TfidfVec.transform([user_query])\n",
    "   vals = cosine_similarity(k, tfidf)\n",
    "   index = 0\n",
    "   val_with_index = []\n",
    "   for val in vals[0]:\n",
    "        tuple1 = (val, index)\n",
    "        val_with_index.append(tuple1)\n",
    "        index = index + 1\n",
    "   val_with_index.sort(key=sortFirst, reverse=True)\n",
    "   return val_with_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "319fc390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_tags():\n",
    "    tags = []\n",
    "    for sentence in sent_token:\n",
    "        possible_tags = sentence.lower().split(\" \")[1:-1]\n",
    "        for pt in possible_tags:\n",
    "            if pt not in tags:\n",
    "                tags.append(pt)\n",
    "    return tags\n",
    "tags = seperate_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df572194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(user_query):\n",
    "    tags_in_query = []\n",
    "    words_in_query = user_query.lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).split(\" \")\n",
    "    rating_in_query = re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", user_query)\n",
    "    for wiq in words_in_query:\n",
    "        if wiq in tags:\n",
    "            tags_in_query.append(wiq)\n",
    "    sorted_similar_sent = response(user_query)\n",
    "    found_rest_index = []\n",
    "    for similar_val in sorted_similar_sent:\n",
    "        sent = sent_token[similar_val[1]].lower()\n",
    "        tag_found_count = 0\n",
    "        for tag_search in tags_in_query:\n",
    "            if tag_search in sent:\n",
    "                tag_found_count = tag_found_count + 1\n",
    "        if tag_found_count == 0:\n",
    "            found_rest_index.sort()\n",
    "            return found_rest_index, rating_in_query\n",
    "        if tag_found_count == len(tags_in_query):\n",
    "            found_rest_index.append(int(sent.split(\" \")[0]))\n",
    "    found_rest_index.sort()\n",
    "    return found_rest_index, rating_in_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c588e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rests(user_input):\n",
    "    possible_rest_index, rating_in_query = query(user_input)\n",
    "    rating_in_query = float(rating_in_query[0]) if len(rating_in_query)>0 else 0\n",
    "    possible_name_rating_pairs = []\n",
    "    for pri in possible_rest_index:\n",
    "        possible_name_rating_pairs.append(name_rating[pri])\n",
    "    possible_name_rating_pairs.sort(key=sortFirst, reverse=True)\n",
    "    if len(possible_name_rating_pairs) == 0:\n",
    "        print(\"ChatBot: Sorry, cannot find any restaurant of that kind.\")\n",
    "        return\n",
    "    desired_restauants = []\n",
    "    for possible_name_rating_pair in possible_name_rating_pairs:\n",
    "        if possible_name_rating_pair[0] < rating_in_query:\n",
    "                break\n",
    "        desired_restauants.append(possible_name_rating_pair[1])\n",
    "    if len(desired_restauants) == 0:\n",
    "        print(\"ChatBot: Sorry, cannot find a restaurant with that rating\")\n",
    "        return\n",
    "    print(\"ChatBot: Found \" + str(len(desired_restauants)) + \" restaurants.\")\n",
    "    for x in range(0,min(5, len(desired_restauants))):\n",
    "        print(x + 1, \" \",desired_restauants[x])\n",
    "    if len(desired_restauants) > 5:\n",
    "        print(\"ChatBot: Do you want to see all?\")\n",
    "        print(\"User:\", end=\" \")\n",
    "        user_input1 = input().lower()\n",
    "        if user_input1 == \"yes\":\n",
    "            for x in range(5,len(desired_restauants)):\n",
    "                print(x + 1, \" \",desired_restauants[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f437203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_city_in_query(query):\n",
    "    for city_tag in restaurant_intent_data['intents'][1]['patterns']:\n",
    "        if city_tag in query:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_tags_present(query):\n",
    "    for tag in restaurant_intent_data['intents'][0]['patterns']:\n",
    "        if tag in query:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb2a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot_restaurant(user_input):\n",
    "        is_city_present = find_city_in_query(user_input)\n",
    "        if not is_city_present:\n",
    "            print(\"ChatBot:\", np.random.choice(restaurant_intent_data['intents'][1]['responses']))\n",
    "            print(\"User:\", end=\" \")\n",
    "            user_input1 = input().lower()\n",
    "            user_input = user_input + \" \" + user_input1\n",
    "            is_city_present = find_city_in_query(user_input)\n",
    "            if not is_city_present:\n",
    "                print(\"ChatBot: Sorry, I cannot search for that city\")\n",
    "                return\n",
    "        is_tags_present = find_tags_present(user_input)\n",
    "        find_best_rests(user_input)\n",
    "        if not is_tags_present:\n",
    "                print(\"ChatBot:\", np.random.choice(restaurant_intent_data['intents'][0]['responses']) + \" Write No if you have already found your restaurant.\")\n",
    "                print(\"User:\", end=\" \")\n",
    "                user_input = user_input + \" \" + input().lower()\n",
    "                if user_input.split(\" \")[-1] == \"no\":\n",
    "                    return\n",
    "                find_best_rests(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a848624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_training_sentences = []\n",
    "initial_training_labels = []\n",
    "initial_labels = []\n",
    "initial_responses = []\n",
    "def initial_intent_document():\n",
    "    for intent in initial_intent_data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            initial_training_sentences.append(pattern)\n",
    "            initial_training_labels.append(intent['tag'])\n",
    "        initial_responses.append(intent['responses'])\n",
    "\n",
    "        if intent['tag'] not in initial_labels:\n",
    "            initial_labels.append(intent['tag'])\n",
    "initial_intent_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea7958d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVec_initial_intent = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "tfidf_initial_intent = TfidfVec_initial_intent.fit_transform(initial_training_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c185064",
   "metadata": {},
   "source": [
    "# Intent Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d2752a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot():\n",
    "    print(\"Start your conversation with the chat bot\")\n",
    "    while True:\n",
    "        print(\"User:\", end=\" \")\n",
    "        user_query = input().lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "        k = TfidfVec_initial_intent.transform([user_query])\n",
    "        vals = cosine_similarity(k, tfidf_initial_intent)\n",
    "        idx = vals.argsort()[0][-1]\n",
    "        flat = vals.flatten()\n",
    "        flat.sort()\n",
    "        req_tfidf = flat[-1]\n",
    "        if req_tfidf == 0:\n",
    "            print(\"ChatBot: Sorry, could not understand you please try again.\")\n",
    "        else:\n",
    "            if initial_training_labels[idx] == \"movie_chat_bot\":\n",
    "                chat_bot_movie(user_query)\n",
    "            elif initial_training_labels[idx] == \"restaurant_chat_pot\":\n",
    "                chat_bot_restaurant(user_query)\n",
    "            else:\n",
    "                print(\"ChatBot:\", np.random.choice(initial_responses[initial_labels.index(initial_training_labels[idx])]))\n",
    "                if initial_training_labels[idx] == \"goodbye\":\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start your conversation with the chat bot\n",
      "User: Hi\n",
      "ChatBot: Hi there\n",
      "User: find me a Vegan restaurant in london\n",
      "ChatBot: Found 2784 restaurants.\n",
      "1   R & H cafe gallery\n",
      "2   Liman Restaurant\n",
      "3   Holy Smoke\n",
      "4   The Clink Restaurant\n",
      "5   Bar 61 Restaurant\n",
      "ChatBot: Do you want to see all?\n",
      "User: find me a Vegan restaurant in london with rating 5\n",
      "User: find me a Vegan restaurant in london with rating 5\n",
      "ChatBot: Found 191 restaurants.\n",
      "1   R & H cafe gallery\n",
      "2   Liman Restaurant\n",
      "3   Holy Smoke\n",
      "4   The Clink Restaurant\n",
      "5   Bar 61 Restaurant\n",
      "ChatBot: Do you want to see all?\n",
      "User: yes\n",
      "6   Taste Of Nawab\n",
      "7   Pizza Union Aldgate\n",
      "8   Core by Clare Smyth\n",
      "9   taNgia\n",
      "10   Gastronhome\n",
      "11   Zeret Kitchen\n",
      "12   The Five Fields\n",
      "13   Peninsula Restaurant\n",
      "14   Kibele Restaurant & Bar\n",
      "15   The Calabash of Culture\n",
      "16   Trattoria Raffaele\n",
      "17   Lorne Restaurant\n",
      "18   Daphne Restaurant\n",
      "19   Shahi Pakwaan\n",
      "20   Lentil\n",
      "21   Pizzetta Pizza\n",
      "22   Zala grill\n",
      "23   Rock Star Sushi Bar\n",
      "24   The Lounge Cafe\n",
      "25   Saka Maka cafe\n",
      "26   L'Elysee Artisan Cafe and Patisserie\n",
      "27   Cafe Che-Men\n",
      "28   Oi Vita Pizzeria\n",
      "29   Adore Remo\n",
      "30   Magic Falafel\n",
      "31   Alexandrie Restaurant\n",
      "32   Restaurant Flat Three\n",
      "33   Fast Break\n",
      "34   KataKata\n",
      "35   Sorrento In\n",
      "36   Il Primo Ristorante\n",
      "37   Cafe Van Gogh\n",
      "38   Olde Goa\n",
      "39   Pham house\n",
      "40   Rullo's Pizzeria\n",
      "41   Volare\n",
      "42   Wassouf Lounge\n",
      "43   Made in South Pizzeria\n",
      "44   Frog By Adam Handling\n",
      "45   Alcedo Bistro & Bar\n",
      "46   Franzina Trattoria\n",
      "47   Meraki Grill\n",
      "48   Viet Baguette Ltd\n",
      "49   PickyWops\n",
      "50   Casa Tua Camden\n",
      "51   Mazaya\n",
      "52   Fig Tree\n",
      "53   Sidi Bou - London\n",
      "54   Lambo Bar And Restaurant\n",
      "55   Les Douceurs de la Tentation\n",
      "56   Home SW15\n",
      "57   Fine Foods - Locanda Del Melo\n",
      "58   Bonoo\n",
      "59   129HRD\n",
      "60   Hasu\n",
      "61   Mr Falafel\n",
      "62   Apollo Restaurant\n",
      "63   Killer Tomato\n",
      "64   Suvlaki Shoreditch\n",
      "65   Spanish Particular\n",
      "66   Alla Salute\n",
      "67   Olive Cafe\n",
      "68   Kolam South Indian Restaurant\n",
      "69   Pizza X Drink\n",
      "70   Saponara\n",
      "71   Pickled Fred\n",
      "72   Tanakatsu\n",
      "73   The Spice Indian Restaurant\n",
      "74   The Grove\n",
      "75   Massawa\n",
      "76   Festa Sul Prato\n",
      "77   Gulab tandoori n1\n",
      "78   Cafe de Provence\n",
      "79   Lattakia\n",
      "80   JIN SUSHI\n",
      "81   Nivens Fine Foods\n",
      "82   Tommi's Burger Joint, Berwick St, Soho\n",
      "83   VBurger Camden\n",
      "84   E-Four Indian Fusion\n",
      "85   The English Grill\n",
      "86   Victory Mansion\n",
      "87   Trattoria Terra\n",
      "88   Sikulo Italian Cafe & Restaurant\n",
      "89   CookDaily\n",
      "90   Kouzina Express\n",
      "91   The Continental Pantry\n",
      "92   Asmak albasha\n",
      "93   The Italians\n",
      "94   Nanashi\n",
      "95   Le Tran Cafe\n",
      "96   Panzerotto Blues\n",
      "97   Pizzeria Pinocchio\n",
      "98   Simply Tasty Cafe&Kitchen\n",
      "99   India Garden\n",
      "100   L'oro di Napoli\n",
      "101   Mamma Dough - Peckham\n",
      "102   Pizzeria Di Camden\n",
      "103   Malaysian Deli\n",
      "104   The Fusion by Kai\n",
      "105   Nepal Authentic Dining\n",
      "106   Carpe Diem\n",
      "107   Le Merlin\n",
      "108   Sumika\n",
      "109   Norris + Knight\n",
      "110   Cafe 12\n",
      "111   Hiba Street\n",
      "112   Qasioun Restaurant\n",
      "113   Tummy Kom4ort Nigerian Restaurant (African Cuisine)\n",
      "114   Stables Cafe\n",
      "115   Memsaab Indian Cuisine\n",
      "116   Peers' Dining Room\n",
      "117   Miki's Paradise\n",
      "118   Cafe Pronto\n",
      "119   Wild Thyme\n",
      "120   Baristas Fusion Cafe\n",
      "121   The Greenhouse Deptford\n",
      "122   Cravings La Carreta\n",
      "123   Tiramisu Cafe\n",
      "124   Delizie D'italia\n",
      "125   Camden Pizza Co\n",
      "126   Cafe Green\n",
      "127   Bariba' Italian Deli\n",
      "128   Curtis Caribbean Grill and Specialty Cakes\n",
      "129   La Cafeteria\n",
      "130   Zena\n",
      "131   Rumi Restaurant\n",
      "132   Paradise Parlour\n",
      "133   Taco Queen\n",
      "134   La Violetta\n",
      "135   Simya Korean Restaurant\n",
      "136   Jimmy and the Bee\n",
      "137   Thai Cafe Restaurant\n",
      "138   The Feel Good Cafe\n",
      "139   HealthyWealthy\n",
      "140   Pho Ta\n",
      "141   Cafe Paolo\n",
      "142   Kafeteryam Sandwich Bar\n",
      "143   Vicki's\n",
      "144   Sista Barista\n",
      "145   Midori Sushi\n",
      "146   Asoo's\n",
      "147   Bel & Nev\n",
      "148   Quilombero\n",
      "149   Highams Lounge\n",
      "150   The Chelsea Cellar\n",
      "151   MENOO ECLECTIC FOODS\n",
      "152   Smaka\n",
      "153   Tea Darling\n",
      "154   Paglia e Fieno\n",
      "155   Pacific Social Club\n",
      "156   Marcel & Sons\n",
      "157   Omar's Place\n",
      "158   Piadina Genuina\n",
      "159   Oven East\n",
      "160   Moka East Cafe at the View Tube\n",
      "161   Tastes of the Nile\n",
      "162   Aqua Deli\n",
      "163   London Velo\n",
      "164   Black Olive Cooks\n",
      "165   Skip Garden and Kitchen\n",
      "166   Zakuski\n",
      "167   The Dartmouth Arms\n",
      "168   Harris HT\n",
      "169   Anima Sarda Italian Restaurant\n",
      "170   Art Deli\n",
      "171   The Lounge Cafe\n",
      "172   Spier's Salads\n",
      "173   Lena's Bar & Kitchen\n",
      "174   The Vurger Co\n",
      "175   Foodinthemiddle\n",
      "176   Al Farah Cafe\n",
      "177   Hoa Phuong\n",
      "178   Westfield White City Ariel Way\n",
      "179   Oracle Organic\n",
      "180   The Studio Cafe\n",
      "181   The Falafel Bar\n",
      "182   Stir it up\n",
      "183   Glo!\n",
      "184   Smoke'n'Roll\n",
      "185   Wearecoup\n",
      "186   Gizli Restaurant\n",
      "187   Retreat Cafe\n",
      "188   De Mezka\n",
      "189   Hummus Lina\n",
      "190   SushiQueen\n",
      "191   Bonjour Brioche\n",
      "User: find me a Vegan restaurant\n",
      "ChatBot: I need the city info in order to search the restaurants\n",
      "User: London\n",
      "ChatBot: Found 2784 restaurants.\n",
      "1   R & H cafe gallery\n",
      "2   Liman Restaurant\n",
      "3   Holy Smoke\n",
      "4   The Clink Restaurant\n",
      "5   Bar 61 Restaurant\n",
      "ChatBot: Do you want to see all?\n",
      "User: find me a restaurant in london\n",
      "User: find me a restaurant in london\n",
      "ChatBot: Found 13596 restaurants.\n",
      "1   R & H cafe gallery\n",
      "2   Osteria Romana\n",
      "3   The Oystermen Seafood Bar & Kitchen\n",
      "4   Liman Restaurant\n",
      "5   Holy Smoke\n",
      "ChatBot: Do you want to see all?\n",
      "User: no\n",
      "ChatBot: What kind of speciality you want restaurants to have? Write No if you have already found your restaurant.\n",
      "User: Vegan, dutch\n",
      "ChatBot: Found 1 restaurants.\n",
      "1   My Old Dutch Pancake House\n",
      "User: "
     ]
    }
   ],
   "source": [
    "chat_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5290c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d97a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
